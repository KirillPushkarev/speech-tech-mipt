{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cb18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Iterable, Tuple, List\n",
    "import warnings\n",
    "\n",
    "import editdistance\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sentencepiece\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.data import TokenToIdEncoder\n",
    "from src.models import ConformerLAS, ConformerCTC\n",
    "from src.metrics import WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bb692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model: pl.LightningModule, ckpt_path: str) -> pl.LightningModule:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    wer = WER()\n",
    "    wer.update(refs, hyps)\n",
    "    return wer.compute()[0].item()\n",
    "\n",
    "\n",
    "class GreedyDecoderLAS:\n",
    "    def __init__(self, model: ConformerLAS, max_steps=20):\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def __call__(self, encoded: torch.Tensor) -> str:\n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "\n",
    "        for _ in range(self.max_steps):\n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            sequence_len = tokens_batch.size(-1)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([sequence_len]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_attention_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "        \n",
    "            best_next_token = distribution[0, -1].argmax()\n",
    "            \n",
    "            if best_next_token == self.model.decoder.tokenizer.eos_id():\n",
    "                break\n",
    "\n",
    "            tokens.append(best_next_token.item())\n",
    "        \n",
    "        return self.model.decoder.tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7489a3",
   "metadata": {},
   "source": [
    "# Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd256ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/mnt/c/Users/Kirill/Documents/repos/speech-tech-mipt/week09/asr/../../week07/asr/data/test_opus/farfield/manifest.jsonl'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = os.getcwd() + \"/../../week07/asr/data/test_opus/farfield/manifest.jsonl\"\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d7a33",
   "metadata": {},
   "source": [
    "## LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91eff477",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformer_las_conf = omegaconf.OmegaConf.load(\"./conf/conformer_las.yaml\")\n",
    "conformer_las_conf.val_dataloader.dataset.manifest_name = dataset\n",
    "conformer_las_conf.model.decoder.tokenizer = \"./data/tokenizer/bpe_1024_bos_eos.model\"\n",
    "\n",
    "conformer_las = init_model(\n",
    "    model=ConformerLAS(conf=conformer_las_conf),\n",
    "    ckpt_path=\"./data/conformer_las_2epochs.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1343a50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/479 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55662b46939b4037ac57a2a2915e234f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "las_decoder = GreedyDecoderLAS(conformer_las)\n",
    "\n",
    "refs, hyps_las = [], []\n",
    "\n",
    "for batch in tqdm(conformer_las.val_dataloader()):\n",
    "    features, features_len, targets, target_len = batch\n",
    "\n",
    "    encoded, encoded_len = conformer_las(features, features_len)\n",
    "\n",
    "    batch_size = features.shape[0]\n",
    "    for i in range(batch_size):\n",
    "        encoder_states = encoded[\n",
    "            [i],\n",
    "            :encoded_len[i],\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        ref_tokens = targets[i, :target_len[i]].tolist()\n",
    "\n",
    "        refs.append(\n",
    "            conformer_las.decoder.tokenizer.decode(ref_tokens)\n",
    "        )\n",
    "        hyps_las.append(\n",
    "            las_decoder(encoder_states)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05af7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.42290276288986206"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_las = compute_wer(refs, hyps_las)\n",
    "wer_las"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262680b9",
   "metadata": {},
   "source": [
    "## CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e8ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_hyps(model: ConformerCTC) -> Tuple[List[str], List[str]]:\n",
    "    refs, hyps = [], []\n",
    "\n",
    "    for batch in tqdm(model.val_dataloader()):\n",
    "        features, features_len, targets, target_len = batch\n",
    "        encoded, encoded_len, preds = model(features, features_len)\n",
    "\n",
    "        batch_refs = model.decoder.decode(token_ids=targets, token_ids_length=target_len)\n",
    "        batch_hyps = model.decoder.decode(\n",
    "            token_ids=preds, token_ids_length=encoded_len, unique_consecutive=True\n",
    "        )\n",
    "\n",
    "        refs.extend(\n",
    "            batch_refs\n",
    "        )\n",
    "        hyps.extend(\n",
    "            batch_hyps\n",
    "        )\n",
    "\n",
    "    return refs, hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76da07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformer_ctc_conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc.yaml\")\n",
    "conformer_ctc_conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc = init_model(\n",
    "    model=ConformerCTC(conf=conformer_ctc_conf),\n",
    "    ckpt_path=\"./data/conformer_7epochs_state_dict.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/479 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5aa789fb8d84f6cb9c8e7adb57a02eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "refs, hyps_ctc = decode_ctc_hyps(conformer_ctc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4247196316719055"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_ctc = compute_wer(refs, hyps_ctc)\n",
    "wer_ctc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64281db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformer_ctc_wide_conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc_wide.yaml\")\n",
    "conformer_ctc_wide_conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc_wide = init_model(\n",
    "    model=ConformerCTC(conf=conformer_ctc_wide_conf),\n",
    "    ckpt_path=\"./data/conformer_wide_7epochs_state_dict.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/479 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "610c5869b9724b8fa2e07242fb8d3a7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "refs, hyps_ctc_wide = decode_ctc_hyps(conformer_ctc_wide)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bdda104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.3700787425041199"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_ctc_wide = compute_wer(refs, hyps_ctc_wide)\n",
    "wer_ctc_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60776f4",
   "metadata": {},
   "source": [
    "# ROVER: Recognizer Output Voting Error Reduction — 5 points\n",
    "\n",
    "* [A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)](https://ieeexplore.ieee.org/document/659110)\n",
    "* [Improved ROVER using Language Model Information](https://www-tlp.limsi.fr/public/asr00_holger.pdf)\n",
    "\n",
    "Alignment + Voting\n",
    "\n",
    "![](./images/rover_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "167e04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crowdkit.aggregation.texts import ROVER"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a DataFrame with columns \"task\" (one example from the dataset), \"worker\" (model), \"text\" (predicted text), \"priority\" (better model has lower priority):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d74139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      task    worker                                        text  priority\n3832     0  ctc_wide                                 джой хватит         0\n0        0       las                                 джой хватит         1\n1916     0       ctc                                 джой хлатит         2\n3833     1  ctc_wide   салют вызов светлане васильевне виколенко         0\n1        1       las  салют вызов светлане васильевневый колемка         1\n1917     1       ctc   салют вызов светлане васильевне воколенко         2\n3834     2  ctc_wide                                 салют латит         0\n2        2       las                        салют играть в латис         1\n1918     2       ctc                                 салютсватив         2\n3835     3  ctc_wide        джой звонок юрию ивановичу царьклову         0\n3        3       las               джой звонок юрьевичу зарковой         1\n1919     3       ctc         джой звонок юрью ивановичу царькову         2\n3836     4  ctc_wide                      джой выть десть ценари         0\n4        4       las                         джой вытти сценариа         1\n1920     4       ctc                      джой быдь десятьценари         2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task</th>\n      <th>worker</th>\n      <th>text</th>\n      <th>priority</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3832</th>\n      <td>0</td>\n      <td>ctc_wide</td>\n      <td>джой хватит</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>las</td>\n      <td>джой хватит</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1916</th>\n      <td>0</td>\n      <td>ctc</td>\n      <td>джой хлатит</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3833</th>\n      <td>1</td>\n      <td>ctc_wide</td>\n      <td>салют вызов светлане васильевне виколенко</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>las</td>\n      <td>салют вызов светлане васильевневый колемка</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1917</th>\n      <td>1</td>\n      <td>ctc</td>\n      <td>салют вызов светлане васильевне воколенко</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3834</th>\n      <td>2</td>\n      <td>ctc_wide</td>\n      <td>салют латит</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>las</td>\n      <td>салют играть в латис</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1918</th>\n      <td>2</td>\n      <td>ctc</td>\n      <td>салютсватив</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3835</th>\n      <td>3</td>\n      <td>ctc_wide</td>\n      <td>джой звонок юрию ивановичу царьклову</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>las</td>\n      <td>джой звонок юрьевичу зарковой</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1919</th>\n      <td>3</td>\n      <td>ctc</td>\n      <td>джой звонок юрью ивановичу царькову</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3836</th>\n      <td>4</td>\n      <td>ctc_wide</td>\n      <td>джой выть десть ценари</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>las</td>\n      <td>джой вытти сценариа</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1920</th>\n      <td>4</td>\n      <td>ctc</td>\n      <td>джой быдь десятьценари</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_input_las = [(i, \"las\", hyp, 1) for i, hyp in enumerate(hyps_las)]\n",
    "dataframe_input_ctc = [(i, \"ctc\", hyp, 2) for i, hyp in enumerate(hyps_ctc)]\n",
    "dataframe_input_ctc_wide = [(i, \"ctc_wide\", hyp, 0) for i, hyp in enumerate(hyps_ctc_wide)]\n",
    "dataframe_input = [*dataframe_input_las, *dataframe_input_ctc, *dataframe_input_ctc_wide]\n",
    "aggregate_hyps = pd.DataFrame.from_records(dataframe_input, columns=[\"task\", \"worker\", \"text\", \"priority\"]).sort_values(by=[\"task\", \"priority\"])\n",
    "aggregate_hyps.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1916 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99460ee85ecb4482ae6172e53cde4898"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "task\n0                                  джой хватит\n1    салют вызов светлане васильевне воколенко\n2                                  салют латит\n3         джой звонок юрью ивановичу царьклову\n4                      джой десть десятьценари\nName: agg_text, dtype: object"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = lambda s: s.split(' ')\n",
    "detokenizer = lambda tokens: ' '.join(tokens)\n",
    "hyps_rover = ROVER(tokenizer=tokenizer, detokenizer=detokenizer, silent=False).fit_predict(aggregate_hyps)\n",
    "hyps_rover.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.35874491930007935"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_rover = compute_wer(refs, hyps_rover)\n",
    "wer_rover"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER improvement by ROVER: 0.011333823204040527\n"
     ]
    }
   ],
   "source": [
    "print(f\"WER improvement by ROVER: {min(wer_las, wer_ctc, wer_ctc_wide) - wer_rover}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregated hypotheses by ROVER have lower WER than hypotheses by any of single models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "fd329aa4",
   "metadata": {},
   "source": [
    "# MBR: Minimum Bayes Risk — 5 points\n",
    "\n",
    "\n",
    "* [Minimum Bayes Risk Decoding and System\n",
    "Combination Based on a Recursion for Edit Distance](https://danielpovey.com/files/csl11_consensus.pdf)\n",
    "* [mbr-decoding blog-post](https://suzyahyah.github.io/bayesian%20inference/machine%20translation/2022/02/15/mbr-decoding.html)\n",
    "* [Combination of end-to-end and hybrid models for speech recognition](http://www.interspeech2020.org/uploadfile/pdf/Tue-1-8-4.pdf)\n",
    "\n",
    "![](./images/mbr_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "hyps_by_all_models = np.array(list(zip(hyps_las, hyps_ctc, hyps_ctc_wide)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "batch_size = conformer_las_conf.val_dataloader.batch_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e1fb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mwer(edit_distances: np.ndarray, hyp_probabilities: np.ndarray) -> float:\n",
    "    return np.dot(edit_distances, hyp_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def get_edit_distance_matrices_for_batch(hyps_batch: List[List[str]]) -> torch.Tensor:\n",
    "    batch_size = len(hyps_batch)\n",
    "    models_count = len(hyps_batch[0])\n",
    "    distance_matrix = torch.empty((batch_size, models_count, models_count))\n",
    "    for i, hyps_for_single_sample in enumerate(hyps_batch):\n",
    "        for j in range(len(hyps_for_single_sample)):\n",
    "            for k in range(len(hyps_for_single_sample)):\n",
    "                if j < k:\n",
    "                    hyp1_tokens = hyps_for_single_sample[j].split()\n",
    "                    hyp2_tokens = hyps_for_single_sample[k].split()\n",
    "                    dist = editdistance.eval(hyp1_tokens, hyp2_tokens)\n",
    "                    distance_matrix[i, j, k] = dist\n",
    "                elif j == k:\n",
    "                    distance_matrix[i, j, k] = 0\n",
    "                else:\n",
    "                    distance_matrix[i, j, k] = distance_matrix[i, k, j]\n",
    "\n",
    "    return distance_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def normalize_probs(hyps_probs: torch.Tensor):\n",
    "    return hyps_probs / hyps_probs.sum(dim=-1).unsqueeze(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "class LASLikelihoodEstimator:\n",
    "    def __init__(self, model: ConformerLAS):\n",
    "        self.model = model\n",
    "        self.tokenizer: sentencepiece.SentencePieceProcessor = self.model.decoder.tokenizer\n",
    "\n",
    "    def __call__(self, encoder_result: Tuple[torch.Tensor, torch.Tensor], hyps: List[str]) -> torch.Tensor:\n",
    "        encoder_state, encoder_state_len = encoder_result\n",
    "\n",
    "        hyps_tokenized = [\n",
    "                torch.tensor([self.tokenizer.bos_id()] + self.tokenizer.encode(hyp) + [self.tokenizer.eos_id()], dtype=torch.long)\n",
    "                for hyp in hyps\n",
    "        ]\n",
    "        hyps_lengths = torch.tensor([len(hyp) - 1 for hyp in hyps_tokenized], dtype=torch.long)\n",
    "        hyps_padded = torch.nn.utils.rnn.pad_sequence(hyps_tokenized, batch_first=True).long()\n",
    "        hyps_padded_length = hyps_padded.size(-1) - 1\n",
    "\n",
    "        encoded_pad_mask = self.model.make_pad_mask(encoder_state_len)\n",
    "        target_pad_mask = self.model.make_pad_mask(hyps_lengths)\n",
    "        target_att_mask = self.model.make_attention_mask(torch.tensor([hyps_padded_length]))\n",
    "\n",
    "        logits = self.model.decoder(\n",
    "            encoded=encoder_state, encoded_pad_mask=~encoded_pad_mask,\n",
    "            target=hyps_padded[:, :-1], target_attention_mask=target_att_mask, target_pad_mask=~target_pad_mask\n",
    "        )\n",
    "\n",
    "        # select logits corresponding to tokens in hyps\n",
    "        hyps_tokens_logits = torch.gather(input=logits, dim=2, index=hyps_padded[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
    "        hyps_probs = torch.prod(torch.exp(hyps_tokens_logits) / torch.sum(torch.exp(logits), dim=2) + ~target_pad_mask, dim=1)\n",
    "\n",
    "        return hyps_probs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class CTCLikelihoodEstimator:\n",
    "    def __init__(self, model_config, model: ConformerCTC):\n",
    "        self.model = model\n",
    "        self.tokenizer = lambda sentence: list(sentence)\n",
    "        self.token_to_id_encoder = TokenToIdEncoder.from_model_config(model_config.model)\n",
    "\n",
    "    def __call__(self, encoder_result: Tuple[torch.Tensor, torch.Tensor, torch.Tensor], hyps: List[str]) -> torch.Tensor:\n",
    "        logprobs, encoded_len, preds = encoder_result\n",
    "\n",
    "        hyps_tokenized = [\n",
    "            torch.tensor([self.token_to_id_encoder.encode(token) for token in self.tokenizer(hyp)], dtype=torch.long)\n",
    "            for hyp in hyps\n",
    "        ]\n",
    "        hyps_lengths = torch.tensor([len(hyp) for hyp in hyps_tokenized], dtype=torch.long)\n",
    "        hyps_padded = torch.nn.utils.rnn.pad_sequence(hyps_tokenized, batch_first=True).long()\n",
    "\n",
    "        loss = self.model.ctc_loss(\n",
    "            logprobs.transpose(1, 0), hyps_padded, encoded_len, hyps_lengths\n",
    "        )\n",
    "        hyps_probs = torch.exp(-loss)\n",
    "\n",
    "        return hyps_probs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torch.tensor([wer_las, wer_ctc, wer_ctc_wide]) / (wer_las + wer_ctc + wer_ctc_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/479 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b98f32d4364e4c0aab493cc26d009074"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "las_likelihood_estimator = LASLikelihoodEstimator(conformer_las)\n",
    "ctc_likelihood_estimator = CTCLikelihoodEstimator(conformer_ctc_conf, conformer_ctc)\n",
    "ctc_wide_likelihood_estimator = CTCLikelihoodEstimator(conformer_ctc_wide_conf, conformer_ctc_wide)\n",
    "\n",
    "mbr_dataloader = conformer_las.val_dataloader()\n",
    "mbr_tokenizer = conformer_las.decoder.tokenizer\n",
    "\n",
    "ref, hyps_mbr = [], []\n",
    "\n",
    "for batch_index, batch in enumerate(tqdm(mbr_dataloader)):\n",
    "    features, features_len, target, target_len = batch\n",
    "\n",
    "    hyps_batch = hyps_by_all_models[batch_index * batch_size: (batch_index + 1) * batch_size]\n",
    "    hyps_las_batch = hyps_batch[:, 0]\n",
    "    hyps_ctc_batch = hyps_batch[:, 1]\n",
    "    hyps_ctc_wide_batch = hyps_batch[:, 2]\n",
    "\n",
    "    las_encoder_result = conformer_las(features, features_len)\n",
    "    ctc_encoder_result = conformer_ctc(features, features_len)\n",
    "    ctc_wide_encoder_result = conformer_ctc_wide(features, features_len)\n",
    "\n",
    "    distance_matrices = get_edit_distance_matrices_for_batch(hyps_batch)\n",
    "\n",
    "    las_las_likelihood = las_likelihood_estimator(las_encoder_result, hyps_las_batch)\n",
    "    las_ctc_likelihood = las_likelihood_estimator(las_encoder_result, hyps_ctc_batch)\n",
    "    las_ctc_wide_likelihood = las_likelihood_estimator(las_encoder_result, hyps_ctc_wide_batch)\n",
    "\n",
    "    ctc_las_likelihood = ctc_likelihood_estimator(ctc_encoder_result, hyps_las_batch)\n",
    "    ctc_ctc_likelihood = ctc_likelihood_estimator(ctc_encoder_result, hyps_ctc_batch)\n",
    "    ctc_ctc_wide_likelihood = ctc_likelihood_estimator(ctc_encoder_result, hyps_ctc_wide_batch)\n",
    "\n",
    "    ctc_wide_las_likelihood = ctc_wide_likelihood_estimator(ctc_wide_encoder_result, hyps_las_batch)\n",
    "    ctc_wide_ctc_likelihood = ctc_wide_likelihood_estimator(ctc_wide_encoder_result, hyps_ctc_batch)\n",
    "    ctc_wide_ctc_wide_likelihood = ctc_wide_likelihood_estimator(ctc_wide_encoder_result, hyps_ctc_wide_batch)\n",
    "\n",
    "    las_hyp_likelihood = normalize_probs(torch.concat((las_las_likelihood.unsqueeze(-1), las_ctc_likelihood.unsqueeze(-1), las_ctc_wide_likelihood.unsqueeze(-1)), dim=-1))\n",
    "    ctc_hyp_likelihood = normalize_probs(torch.concat((ctc_las_likelihood.unsqueeze(-1), ctc_ctc_likelihood.unsqueeze(-1), ctc_ctc_wide_likelihood.unsqueeze(-1)), dim=-1))\n",
    "    ctc_wide_hyp_likelihood = normalize_probs(torch.concat((ctc_wide_las_likelihood.unsqueeze(-1), ctc_wide_ctc_likelihood.unsqueeze(-1), ctc_wide_ctc_wide_likelihood.unsqueeze(-1)), dim=-1))\n",
    "\n",
    "    hyps_likelihood = torch.concat((las_hyp_likelihood, ctc_hyp_likelihood, ctc_wide_hyp_likelihood), dim=-1).view(-1, 3, 3)\n",
    "\n",
    "    mwer_scores = []\n",
    "    for element_in_batch_index in range(len(batch)):\n",
    "        hyp_distances_for_sample = distance_matrices[element_in_batch_index]\n",
    "        hyps_likelihood_for_sample = hyps_likelihood[element_in_batch_index]\n",
    "\n",
    "        mwer_score_las = ((hyp_distances_for_sample[0] * hyps_likelihood_for_sample).sum(dim=-1) * model_weights).sum()\n",
    "        mwer_score_ctc = ((hyp_distances_for_sample[1] * hyps_likelihood_for_sample).sum(dim=-1) * model_weights).sum()\n",
    "        mwer_score_ctc_wide = ((hyp_distances_for_sample[2] * hyps_likelihood_for_sample).sum(dim=-1) * model_weights).sum()\n",
    "        mwer_scores.append(torch.tensor([mwer_score_las, mwer_score_ctc, mwer_score_ctc_wide]).view(1, -1))\n",
    "\n",
    "    mwer_scores_tensor = torch.concat(mwer_scores)\n",
    "    top_hyp_per_input = mwer_scores_tensor.argmin(dim=-1)\n",
    "\n",
    "    refs.extend(\n",
    "        [mbr_tokenizer.decode(target_tokens[:target_len[j]].tolist()) for j, target_tokens in enumerate(target)]\n",
    "    )\n",
    "    hyps_mbr.extend(\n",
    "        [hyps_batch[j][top_hyp_per_input[j]] for j in range(len(hyps_batch))]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad2c3499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.34156525135040283"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_mbr = compute_wer(refs, hyps_mbr)\n",
    "wer_mbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER improvement by MBR: 0.02851349115371704\n"
     ]
    }
   ],
   "source": [
    "print(f\"WER improvement by MBR: {min(wer_las, wer_ctc, wer_ctc_wide) - wer_mbr}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregated hypotheses by MBR have lower WER than hypotheses by any of the single models and hypotheses obtained by applying ROVER."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "                          Hypothesis from MBR  \\\n0                                 джой хватит   \n1   салют вызов светлане васильевне виколенко   \n2                                 салют латит   \n3         джой звонок юрью ивановичу царькову   \n4                      джой быдь десятьценари   \n5                                 салют вэйте   \n6                              салют закройся   \n7                       салют набери данилова   \n8                           сбер мне нравится   \n9                              салют прекрати   \n10                                сбер гранче   \n11    салют звонок юрию владимировичу волкову   \n12                                афина вэйти   \n13                        сбер выти с ценария   \n14                     джой приложение сверни   \n\n                                    Reference  \n0                                 джой хватит  \n1   салют вызов светлане васильевне николенко  \n2                                салют хватит  \n3         джой звонок юрию ивановичу царькову  \n4                      джой выйти из сценария  \n5                                 салют выйти  \n6                              салют закройся  \n7                       салют набери данилова  \n8                           сбер мне нравится  \n9                              салют прекрати  \n10                                сбер громче  \n11    салют звонок юрию владимировичу волкову  \n12                                афина выйти  \n13                     сбер выйти из сценария  \n14                     джой приложение сверни  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hypothesis from MBR</th>\n      <th>Reference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>джой хватит</td>\n      <td>джой хватит</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>салют вызов светлане васильевне виколенко</td>\n      <td>салют вызов светлане васильевне николенко</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>салют латит</td>\n      <td>салют хватит</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>джой звонок юрью ивановичу царькову</td>\n      <td>джой звонок юрию ивановичу царькову</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>джой быдь десятьценари</td>\n      <td>джой выйти из сценария</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>салют вэйте</td>\n      <td>салют выйти</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>салют закройся</td>\n      <td>салют закройся</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>салют набери данилова</td>\n      <td>салют набери данилова</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>сбер мне нравится</td>\n      <td>сбер мне нравится</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>салют прекрати</td>\n      <td>салют прекрати</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>сбер гранче</td>\n      <td>сбер громче</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>салют звонок юрию владимировичу волкову</td>\n      <td>салют звонок юрию владимировичу волкову</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>афина вэйти</td>\n      <td>афина выйти</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>сбер выти с ценария</td>\n      <td>сбер выйти из сценария</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>джой приложение сверни</td>\n      <td>джой приложение сверни</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(list(zip(hyps_mbr, refs))[:15], columns=[\"Hypothesis from MBR\", \"Reference\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
